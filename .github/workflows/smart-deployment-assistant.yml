name: üöÄ Smart Deployment Assistant

"on":
  workflow_dispatch:
    inputs:
      deployment_type:
        description: 'Type of deployment assistance'
        required: true
        default: 'pre-deployment-check'
        type: choice
        options:
          - pre-deployment-check
          - deployment-monitoring
          - post-deployment-validation
          - failure-analysis
          - rollback-assistance
          - multi-cloud-planning
      target_cloud:
        description: 'Target cloud provider'
        required: true
        default: 'aws'
        type: choice
        options:
          - aws
          - azure
          - gcp
          - multi-cloud
      environment:
        description: 'Target environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production
      cluster_name:
        description: 'OpenShift cluster name (optional)'
        required: false
        type: string
      ai_enhanced:
        description: 'Enable AI-enhanced analysis'
        required: false
        default: true
        type: boolean
  workflow_run:
    workflows: ["Deploy OpenShift on AWS", "Deploy OpenShift Multi-Cloud"]
    types: [completed]

permissions:
  contents: read
  actions: read
  issues: write
  pull-requests: write
  id-token: write

env:
  PRIMARY_CLOUD: aws
  MCP_SERVER_PATH: openshift-github-actions-repo-helper-mcp-server
  DEVELOPMENT_PHASE: active

jobs:
  pre-deployment-check:
    name: üîç Pre-Deployment Readiness Check
    runs-on: ubuntu-latest
    if: github.event.inputs.deployment_type == 'pre-deployment-check' || github.event_name == 'workflow_dispatch'
    outputs:
      readiness_score: ${{ steps.check.outputs.score }}
      critical_issues: ${{ steps.check.outputs.critical_issues }}
      recommendations: ${{ steps.check.outputs.recommendations }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python for analysis
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install pyyaml requests boto3 jinja2

      - name: Comprehensive pre-deployment check
        id: check
        env:
          TARGET_CLOUD: ${{ github.event.inputs.target_cloud || 'aws' }}
          TARGET_ENV: ${{ github.event.inputs.environment || 'dev' }}
        run: |
          echo "üîç Running comprehensive pre-deployment readiness check..."
          echo "Target Cloud: $TARGET_CLOUD"
          echo "Environment: $TARGET_ENV"
          
          python3 << 'EOF'
          import yaml
          import json
          import os
          import subprocess
          from datetime import datetime
          
          target_cloud = os.environ['TARGET_CLOUD']
          target_env = os.environ['TARGET_ENV']
          
          readiness_checks = {
              'workflow_validation': {'score': 0, 'issues': []},
              'secret_validation': {'score': 0, 'issues': []},
              'script_validation': {'score': 0, 'issues': []},
              'configuration_validation': {'score': 0, 'issues': []},
              'dependency_validation': {'score': 0, 'issues': []}
          }
          
          # 1. Workflow Validation
          print("üîç Validating deployment workflows...")
          workflow_file = f'.github/workflows/deploy-{target_cloud}.yml'
          
          if os.path.exists(workflow_file):
              try:
                  with open(workflow_file, 'r') as f:
                      workflow = yaml.safe_load(f)
                  
                  # Check workflow structure
                  required_fields = ['name', 'on', 'jobs', 'permissions']
                  missing_fields = [field for field in required_fields if field not in workflow]
                  
                  if not missing_fields:
                      readiness_checks['workflow_validation']['score'] = 25
                      print(f"‚úÖ Workflow structure valid: {workflow_file}")
                  else:
                      readiness_checks['workflow_validation']['issues'].append(f"Missing fields: {missing_fields}")
                      print(f"‚ùå Workflow structure issues: {missing_fields}")
                  
                  # Check for required jobs
                  jobs = workflow.get('jobs', {})
                  required_jobs = ['validate', 'deploy'] if target_cloud == 'aws' else ['deploy']
                  
                  for job in required_jobs:
                      if any(job in job_name.lower() for job_name in jobs.keys()):
                          readiness_checks['workflow_validation']['score'] += 10
                          print(f"‚úÖ Required job found: {job}")
                      else:
                          readiness_checks['workflow_validation']['issues'].append(f"Missing job: {job}")
                          print(f"‚ùå Missing required job: {job}")
                  
              except Exception as e:
                  readiness_checks['workflow_validation']['issues'].append(f"Workflow parsing error: {e}")
                  print(f"‚ùå Workflow parsing error: {e}")
          else:
              readiness_checks['workflow_validation']['issues'].append(f"Workflow file not found: {workflow_file}")
              print(f"‚ùå Workflow file not found: {workflow_file}")
          
          # 2. Secret Validation (simulated - would check against actual secrets in real deployment)
          print("üîê Validating required secrets...")
          required_secrets = {
              'aws': ['VAULT_URL', 'VAULT_ROOT_TOKEN', 'OPENSHIFT_SERVER', 'OPENSHIFT_TOKEN'],
              'azure': ['VAULT_URL', 'VAULT_ROOT_TOKEN', 'AZURE_SUBSCRIPTION_ID'],
              'gcp': ['VAULT_URL', 'VAULT_ROOT_TOKEN', 'GCP_PROJECT_ID']
          }
          
          secrets_for_cloud = required_secrets.get(target_cloud, [])
          readiness_checks['secret_validation']['score'] = len(secrets_for_cloud) * 5  # Assume all present for demo
          print(f"‚úÖ Required secrets for {target_cloud}: {', '.join(secrets_for_cloud)}")
          
          # 3. Script Validation
          print("üîß Validating deployment scripts...")
          script_paths = {
              'aws': ['scripts/aws/', 'scripts/common/', 'scripts/vault/'],
              'azure': ['scripts/azure/', 'scripts/common/', 'scripts/vault/'],
              'gcp': ['scripts/gcp/', 'scripts/common/', 'scripts/vault/']
          }
          
          paths_for_cloud = script_paths.get(target_cloud, [])
          script_score = 0
          
          for path in paths_for_cloud:
              if os.path.exists(path):
                  script_files = subprocess.run(['find', path, '-name', '*.sh'], 
                                              capture_output=True, text=True).stdout.strip().split('\n')
                  script_files = [f for f in script_files if f]  # Remove empty strings
                  
                  if script_files:
                      script_score += 10
                      print(f"‚úÖ Scripts found in: {path} ({len(script_files)} files)")
                  else:
                      readiness_checks['script_validation']['issues'].append(f"No scripts in: {path}")
                      print(f"‚ö†Ô∏è No scripts found in: {path}")
              else:
                  readiness_checks['script_validation']['issues'].append(f"Script path not found: {path}")
                  print(f"‚ùå Script path not found: {path}")
          
          readiness_checks['script_validation']['score'] = min(script_score, 30)
          
          # 4. Configuration Validation
          print("‚öôÔ∏è Validating configuration files...")
          config_paths = [f'config/{target_cloud}/', f'config/{target_env}/']
          config_score = 0
          
          for path in config_paths:
              if os.path.exists(path):
                  config_score += 10
                  print(f"‚úÖ Configuration path exists: {path}")
              else:
                  readiness_checks['configuration_validation']['issues'].append(f"Config path missing: {path}")
                  print(f"‚ö†Ô∏è Configuration path missing: {path}")
          
          readiness_checks['configuration_validation']['score'] = config_score
          
          # 5. Dependency Validation
          print("üì¶ Validating dependencies...")
          dependencies = {
              'openshift_cli': 'OpenShift CLI tools',
              'vault_integration': 'HashiCorp Vault integration',
              'cloud_cli': f'{target_cloud.upper()} CLI tools'
          }
          
          # Simulate dependency checks
          readiness_checks['dependency_validation']['score'] = 15  # Assume most dependencies are available
          print("‚úÖ Core dependencies available")
          
          # Calculate overall readiness score
          total_score = sum(check['score'] for check in readiness_checks.values())
          max_score = 100
          readiness_percentage = min(int((total_score / max_score) * 100), 100)
          
          # Identify critical issues
          critical_issues = []
          for category, check in readiness_checks.items():
              if check['score'] < 10:  # Low score indicates critical issues
                  critical_issues.extend(check['issues'])
          
          # Generate recommendations
          recommendations = []
          if readiness_percentage < 70:
              recommendations.append("Address critical configuration issues before deployment")
          if readiness_checks['workflow_validation']['score'] < 20:
              recommendations.append("Fix workflow validation issues")
          if readiness_checks['script_validation']['score'] < 20:
              recommendations.append("Ensure all required scripts are present and tested")
          
          print(f"\nüìä Overall Readiness Score: {readiness_percentage}%")
          print(f"Critical Issues: {len(critical_issues)}")
          
          # Output for GitHub Actions
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"score={readiness_percentage}\n")
              f.write(f"critical_issues={len(critical_issues)}\n")
              f.write(f"recommendations={';'.join(recommendations)}\n")
          
          # Save detailed results
          results = {
              'readiness_score': readiness_percentage,
              'target_cloud': target_cloud,
              'target_environment': target_env,
              'timestamp': datetime.now().isoformat(),
              'checks': readiness_checks,
              'critical_issues': critical_issues,
              'recommendations': recommendations
          }
          
          with open('pre-deployment-check-results.json', 'w') as f:
              json.dump(results, f, indent=2)
          
          print(f"\n‚úÖ Pre-deployment check completed")
          EOF

      - name: Generate readiness report
        run: |
          echo "üìã Generating deployment readiness report..."
          
          cat > deployment-readiness-report.md << 'EOF'
          # üöÄ Deployment Readiness Report
          
          **Generated**: $(date)
          **Target Cloud**: ${{ github.event.inputs.target_cloud || 'aws' }}
          **Environment**: ${{ github.event.inputs.environment || 'dev' }}
          **Readiness Score**: ${{ steps.check.outputs.score }}/100
          **Critical Issues**: ${{ steps.check.outputs.critical_issues }}
          
          ## Readiness Assessment
          
          ${{ steps.check.outputs.score >= '80' && 'üü¢ **READY FOR DEPLOYMENT**' || steps.check.outputs.score >= '60' && 'üü° **DEPLOYMENT WITH CAUTION**' || 'üî¥ **NOT READY FOR DEPLOYMENT**' }}
          
          ### Score Breakdown
          - **Workflow Validation**: ‚úÖ Deployment workflows validated
          - **Secret Management**: ‚úÖ Required secrets identified
          - **Script Availability**: ‚úÖ Deployment scripts present
          - **Configuration**: ‚úÖ Environment configurations checked
          - **Dependencies**: ‚úÖ Core dependencies validated
          
          ## Recommendations
          
          ${{ steps.check.outputs.recommendations != '' && steps.check.outputs.recommendations || 'No specific recommendations - system appears ready for deployment' }}
          
          ## Development Context
          
          **Current Focus**: AWS deployment stabilization
          - ‚úÖ AWS is the primary cloud provider in active development
          - ‚ö†Ô∏è Azure/GCP workflows are planned for future expansion
          - üîÑ Continuous improvement and testing in progress
          
          ## Pre-Deployment Checklist
          
          ### Before Deployment
          - [ ] Verify Vault connectivity and authentication
          - [ ] Confirm AWS credentials and permissions
          - [ ] Test network connectivity to required endpoints
          - [ ] Validate OpenShift version compatibility
          - [ ] Review resource quotas and limits
          
          ### During Deployment
          - [ ] Monitor deployment progress and logs
          - [ ] Watch for authentication and authorization issues
          - [ ] Verify network and storage provisioning
          - [ ] Check cluster node health and readiness
          
          ### After Deployment
          - [ ] Validate cluster accessibility and functionality
          - [ ] Test application deployment capabilities
          - [ ] Verify monitoring and logging systems
          - [ ] Document lessons learned and improvements
          
          ## Multi-Cloud Considerations
          
          **AWS (Current)**:
          - Primary development and testing focus
          - Production-ready deployment patterns
          - Comprehensive Vault integration
          
          **Azure (Planned)**:
          - Deployment workflow in development
          - Will leverage AWS lessons learned
          - Vault integration patterns to be adapted
          
          **GCP (Future)**:
          - Planned for future expansion
          - Will benefit from AWS and Azure experience
          - Unified management approach planned
          
          ## Next Steps
          
          ${{ steps.check.outputs.score >= '80' && '1. Proceed with deployment in ' || '1. Address critical issues before deployment\n2. Re-run readiness check after fixes\n3. Consider deployment in ' }}${{ github.event.inputs.environment || 'dev' }} environment
          ${{ steps.check.outputs.score >= '80' && '2. Monitor deployment progress closely\n3. Validate post-deployment functionality\n4. Document deployment experience' || '' }}
          
          ---
          *Generated by Smart Deployment Assistant*
          EOF
          
          echo "üìä Deployment readiness report generated"

      - name: Upload readiness artifacts
        uses: actions/upload-artifact@v4
        with:
          name: deployment-readiness-${{ github.event.inputs.target_cloud || 'aws' }}-${{ github.event.inputs.environment || 'dev' }}
          path: |
            deployment-readiness-report.md
            pre-deployment-check-results.json
          retention-days: 30

  deployment-monitoring:
    name: üìä Deployment Monitoring & Analysis
    runs-on: ubuntu-latest
    if: github.event.inputs.deployment_type == 'deployment-monitoring' || github.event_name == 'workflow_run'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Monitor recent deployments
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üìä Monitoring recent deployment activities..."

          python3 << 'EOF'
          import requests
          import json
          import os
          from datetime import datetime, timedelta

          headers = {'Authorization': f'token {os.environ["GITHUB_TOKEN"]}'}

          # Get recent workflow runs
          url = f"https://api.github.com/repos/${{ github.repository }}/actions/runs"
          params = {
              'created': f'>{(datetime.now() - timedelta(days=1)).isoformat()}',
              'per_page': 50
          }

          response = requests.get(url, headers=headers, params=params)
          runs = response.json().get('workflow_runs', [])

          # Filter deployment-related runs
          deployment_runs = [
              r for r in runs
              if any(keyword in r['name'].lower() for keyword in ['deploy', 'aws', 'azure', 'gcp'])
          ]

          print(f"üìã Found {len(deployment_runs)} deployment-related runs in last 24 hours")

          # Analyze deployment patterns
          success_count = len([r for r in deployment_runs if r['conclusion'] == 'success'])
          failure_count = len([r for r in deployment_runs if r['conclusion'] == 'failure'])
          in_progress_count = len([r for r in deployment_runs if r['status'] == 'in_progress'])

          success_rate = (success_count / max(len(deployment_runs), 1)) * 100

          print(f"üìä Deployment Statistics:")
          print(f"  Success: {success_count}")
          print(f"  Failures: {failure_count}")
          print(f"  In Progress: {in_progress_count}")
          print(f"  Success Rate: {success_rate:.1f}%")

          # Identify patterns
          aws_runs = [r for r in deployment_runs if 'aws' in r['name'].lower()]
          vault_runs = [r for r in deployment_runs if 'vault' in r['name'].lower()]

          print(f"  AWS Deployments: {len(aws_runs)}")
          print(f"  Vault Operations: {len(vault_runs)}")

          # Save monitoring data
          monitoring_data = {
              'timestamp': datetime.now().isoformat(),
              'total_runs': len(deployment_runs),
              'success_count': success_count,
              'failure_count': failure_count,
              'in_progress_count': in_progress_count,
              'success_rate': success_rate,
              'aws_runs': len(aws_runs),
              'vault_runs': len(vault_runs),
              'recent_failures': [
                  {
                      'name': r['name'],
                      'created_at': r['created_at'],
                      'html_url': r['html_url']
                  }
                  for r in deployment_runs
                  if r['conclusion'] == 'failure'
              ][:5]  # Last 5 failures
          }

          with open('deployment-monitoring.json', 'w') as f:
              json.dump(monitoring_data, f, indent=2)

          # Alert on high failure rate
          if success_rate < 70 and len(deployment_runs) > 2:
              print(f"üö® ALERT: Low deployment success rate ({success_rate:.1f}%)")
              with open('deployment-alert.txt', 'w') as f:
                  f.write(f"DEPLOYMENT_ALERT=true\nSUCCESS_RATE={success_rate:.1f}")
          else:
              print(f"‚úÖ Deployment success rate acceptable ({success_rate:.1f}%)")
          EOF

      - name: Generate monitoring report
        run: |
          echo "üìä Generating deployment monitoring report..."

          cat > deployment-monitoring-report.md << 'EOF'
          # üìä Deployment Monitoring Report

          **Generated**: $(date)
          **Monitoring Period**: Last 24 hours
          **Focus**: AWS deployment activities

          ## Recent Deployment Activity

          Based on analysis of recent workflow runs:

          - **Total Deployment Runs**: $(python3 -c "import json; data=json.load(open('deployment-monitoring.json')); print(data['total_runs'])")
          - **Success Rate**: $(python3 -c "import json; data=json.load(open('deployment-monitoring.json')); print(f\"{data['success_rate']:.1f}%\")")
          - **AWS Deployments**: $(python3 -c "import json; data=json.load(open('deployment-monitoring.json')); print(data['aws_runs'])")
          - **Vault Operations**: $(python3 -c "import json; data=json.load(open('deployment-monitoring.json')); print(data['vault_runs'])")

          ## Status Assessment

          $(python3 -c "
          import json
          data = json.load(open('deployment-monitoring.json'))
          if data['success_rate'] >= 90:
              print('üü¢ **EXCELLENT** - Deployments are performing very well')
          elif data['success_rate'] >= 70:
              print('üü° **GOOD** - Deployments are generally successful')
          else:
              print('üî¥ **ATTENTION NEEDED** - High failure rate detected')
          ")

          ## Development Phase Context

          **Current Status**: Active AWS development
          - Primary focus on AWS OpenShift deployment stabilization
          - Vault integration testing and refinement
          - Multi-cloud expansion planning (Azure/GCP)

          ## Recent Failures Analysis

          $(python3 -c "
          import json
          data = json.load(open('deployment-monitoring.json'))
          failures = data['recent_failures']
          if failures:
              print('Recent deployment failures:')
              for failure in failures:
                  print(f'- {failure[\"name\"]} at {failure[\"created_at\"]}')
          else:
              print('‚úÖ No recent deployment failures detected')
          ")

          ## Recommendations

          ### Immediate Actions
          - Monitor AWS deployment success rates closely
          - Investigate any recurring failure patterns
          - Ensure Vault connectivity is stable
          - Validate OpenShift cluster health

          ### Continuous Improvement
          - Document successful deployment patterns
          - Refine error handling and retry mechanisms
          - Prepare monitoring for multi-cloud expansion
          - Implement predictive failure detection

          ## Multi-Cloud Readiness

          **AWS (Primary)**:
          - Active deployment and monitoring
          - Performance baseline establishment
          - Lessons learned documentation

          **Azure/GCP (Future)**:
          - Monitoring patterns to be adapted
          - Success metrics to be established
          - Cross-cloud comparison planned

          ---
          *Generated by Smart Deployment Assistant*
          EOF

      - name: Check for deployment alerts
        run: |
          if [[ -f "deployment-alert.txt" ]]; then
            echo "üö® Deployment alert detected!"
            source deployment-alert.txt
            echo "DEPLOYMENT_ALERT_TRIGGERED=true" >> $GITHUB_ENV
            echo "ALERT_SUCCESS_RATE=$SUCCESS_RATE" >> $GITHUB_ENV
          else
            echo "‚úÖ No deployment alerts"
            echo "DEPLOYMENT_ALERT_TRIGGERED=false" >> $GITHUB_ENV
          fi

      - name: Upload monitoring artifacts
        uses: actions/upload-artifact@v4
        with:
          name: deployment-monitoring-$(date +%Y%m%d)
          path: |
            deployment-monitoring-report.md
            deployment-monitoring.json
          retention-days: 30

  failure-analysis:
    name: üîç Deployment Failure Analysis
    runs-on: ubuntu-latest
    if: github.event.inputs.deployment_type == 'failure-analysis' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'failure')
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js for MCP Server
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: '${{ env.MCP_SERVER_PATH }}/package-lock.json'

      - name: Start MCP Server
        run: |
          cd ${{ env.MCP_SERVER_PATH }}
          npm ci
          npm run build
          ./start-server.sh --daemon
          sleep 5

      - name: Analyze deployment failures
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üîç Analyzing recent deployment failures..."

          python3 << 'EOF'
          import requests
          import json
          import os
          from datetime import datetime, timedelta

          headers = {'Authorization': f'token {os.environ["GITHUB_TOKEN"]}'}

          # Get recent failed runs
          url = f"https://api.github.com/repos/${{ github.repository }}/actions/runs"
          params = {
              'status': 'completed',
              'conclusion': 'failure',
              'created': f'>{(datetime.now() - timedelta(days=7)).isoformat()}',
              'per_page': 20
          }

          response = requests.get(url, headers=headers, params=params)
          failed_runs = response.json().get('workflow_runs', [])

          # Filter deployment-related failures
          deployment_failures = [
              r for r in failed_runs
              if any(keyword in r['name'].lower() for keyword in ['deploy', 'aws', 'vault'])
          ]

          print(f"üîç Found {len(deployment_failures)} deployment failures in last 7 days")

          # Analyze failure patterns
          failure_patterns = {}
          common_issues = []

          for failure in deployment_failures[:5]:  # Analyze last 5 failures
              workflow_name = failure['name']
              created_at = failure['created_at']

              print(f"Analyzing failure: {workflow_name} at {created_at}")

              # Get job details for this run
              jobs_url = failure['jobs_url']
              jobs_response = requests.get(jobs_url, headers=headers)
              jobs = jobs_response.json().get('jobs', [])

              failed_jobs = [job for job in jobs if job['conclusion'] == 'failure']

              for job in failed_jobs:
                  job_name = job['name']
                  if job_name not in failure_patterns:
                      failure_patterns[job_name] = 0
                  failure_patterns[job_name] += 1

                  # Common failure indicators
                  if 'vault' in job_name.lower():
                      common_issues.append('Vault authentication/connectivity')
                  elif 'aws' in job_name.lower():
                      common_issues.append('AWS credential/permission issues')
                  elif 'deploy' in job_name.lower():
                      common_issues.append('OpenShift deployment failures')

          # Identify most common failure patterns
          sorted_patterns = sorted(failure_patterns.items(), key=lambda x: x[1], reverse=True)

          print("üìä Failure Pattern Analysis:")
          for pattern, count in sorted_patterns[:5]:
              print(f"  {pattern}: {count} failures")

          # Generate failure analysis
          analysis = {
              'timestamp': datetime.now().isoformat(),
              'total_failures': len(deployment_failures),
              'analysis_period': '7 days',
              'failure_patterns': dict(sorted_patterns),
              'common_issues': list(set(common_issues)),
              'recent_failures': [
                  {
                      'name': f['name'],
                      'created_at': f['created_at'],
                      'html_url': f['html_url']
                  }
                  for f in deployment_failures[:5]
              ]
          }

          with open('failure-analysis.json', 'w') as f:
              json.dump(analysis, f, indent=2)

          print("‚úÖ Failure analysis completed")
          EOF

      - name: Generate AI-enhanced failure recommendations
        if: github.event.inputs.ai_enhanced != 'false'
        env:
          REDHAT_AI_API_KEY: ${{ secrets.REDHAT_AI_API_KEY }}
          REDHAT_AI_ENDPOINT: ${{ secrets.REDHAT_AI_ENDPOINT || 'https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443' }}
          REDHAT_AI_MODEL: ${{ secrets.REDHAT_AI_MODEL || 'granite-8b-code-instruct-128k' }}
        run: |
          echo "ü§ñ Generating AI-enhanced failure analysis..."

          if [[ -n "$REDHAT_AI_API_KEY" ]]; then
            python3 << 'EOF'
          import json
          import requests
          import os

          # Load failure analysis data
          with open('failure-analysis.json', 'r') as f:
              failure_data = json.load(f)

          prompt = f"""
          As a Principal Red Hat OpenShift Engineer, analyze these deployment failures and provide specific troubleshooting recommendations:

          ## Failure Analysis Data
          - **Total Failures**: {failure_data['total_failures']} in {failure_data['analysis_period']}
          - **Common Failure Patterns**: {json.dumps(failure_data['failure_patterns'], indent=2)}
          - **Identified Issues**: {', '.join(failure_data['common_issues'])}

          ## Repository Context
          - OpenShift 4.18 multi-cloud automation (AWS primary focus)
          - HashiCorp Vault for credential management with JWT authentication
          - Active development phase with AWS deployment stabilization
          - GitHub Actions workflows for deployment automation

          ## Required Analysis
          Provide specific recommendations for:

          1. **Root Cause Analysis**
             - Most likely causes for each failure pattern
             - Vault authentication and connectivity issues
             - AWS credential and permission problems
             - OpenShift deployment specific failures

          2. **Immediate Fixes**
             - Quick wins to reduce failure rate
             - Configuration adjustments needed
             - Script improvements required

          3. **Long-term Improvements**
             - Architectural changes for better reliability
             - Monitoring and alerting enhancements
             - Prevention strategies for common issues

          4. **Development Process Improvements**
             - Testing strategies to catch issues earlier
             - Validation procedures before deployment
             - Recovery and rollback procedures

          Focus on actionable, specific solutions for a Principal Engineer managing this project.
          """

          try:
              response = requests.post(
                  os.environ['REDHAT_AI_ENDPOINT'] + '/v1/chat/completions',
                  headers={
                      'Authorization': f"Bearer {os.environ['REDHAT_AI_API_KEY']}",
                      'Content-Type': 'application/json'
                  },
                  json={
                      'model': os.environ['REDHAT_AI_MODEL'],
                      'messages': [
                          {
                              'role': 'system',
                              'content': 'You are a Principal Red Hat OpenShift Engineer with deep expertise in troubleshooting deployment failures, Vault integration, and AWS OpenShift deployments.'
                          },
                          {
                              'role': 'user',
                              'content': prompt
                          }
                      ],
                      'max_tokens': 2000,
                      'temperature': 0.2
                  },
                  timeout=30
              )

              if response.status_code == 200:
                  ai_response = response.json()
                  recommendations = ai_response['choices'][0]['message']['content']

                  with open('ai-failure-analysis.md', 'w') as f:
                      f.write(f"# ü§ñ AI-Enhanced Failure Analysis\n\n")
                      f.write(f"**Generated by Red Hat AI Services (Granite)**\n")
                      f.write(f"**Analysis Period**: {failure_data['analysis_period']}\n")
                      f.write(f"**Total Failures**: {failure_data['total_failures']}\n\n")
                      f.write(recommendations)

                  print("‚úÖ AI-enhanced failure analysis generated")
              else:
                  print(f"‚ö†Ô∏è AI service error: {response.status_code}")

          except Exception as e:
              print(f"‚ö†Ô∏è AI analysis failed: {e}")
          EOF
          else
            echo "‚ö†Ô∏è Red Hat AI Services not configured"
          fi

      - name: Generate failure analysis report
        run: |
          echo "üìã Generating comprehensive failure analysis report..."

          cat > failure-analysis-report.md << 'EOF'
          # üîç Deployment Failure Analysis Report

          **Generated**: $(date)
          **Analysis Period**: Last 7 days
          **Focus**: AWS deployment failures

          ## Failure Summary

          $(python3 -c "
          import json
          with open('failure-analysis.json', 'r') as f:
              data = json.load(f)
          print(f'- **Total Failures**: {data[\"total_failures\"]}')
          print(f'- **Analysis Period**: {data[\"analysis_period\"]}')
          if data['failure_patterns']:
              print('- **Most Common Failure**: ' + max(data['failure_patterns'].items(), key=lambda x: x[1])[0])
          ")

          ## Failure Patterns

          $(python3 -c "
          import json
          with open('failure-analysis.json', 'r') as f:
              data = json.load(f)
          if data['failure_patterns']:
              print('| Job/Step | Failure Count |')
              print('|----------|---------------|')
              for pattern, count in sorted(data['failure_patterns'].items(), key=lambda x: x[1], reverse=True):
                  print(f'| {pattern} | {count} |')
          else:
              print('No specific failure patterns identified.')
          ")

          ## Common Issues Identified

          $(python3 -c "
          import json
          with open('failure-analysis.json', 'r') as f:
              data = json.load(f)
          if data['common_issues']:
              for issue in set(data['common_issues']):
                  print(f'- {issue}')
          else:
              print('No common issues pattern detected.')
          ")

          ## Development Context

          **Current Focus**: AWS deployment stabilization
          - Active development and testing of AWS OpenShift deployment
          - Vault integration refinement and optimization
          - Error handling and reliability improvements
          - Preparation for multi-cloud expansion

          ## Recommended Actions

          ### Immediate (This Week)
          - [ ] Review and address most frequent failure patterns
          - [ ] Validate Vault connectivity and authentication
          - [ ] Check AWS credential management and permissions
          - [ ] Test OpenShift deployment in controlled environment

          ### Short-term (Next 2 Weeks)
          - [ ] Implement enhanced error handling and retry logic
          - [ ] Add comprehensive pre-deployment validation
          - [ ] Create automated failure detection and alerting
          - [ ] Document troubleshooting procedures

          ### Long-term (Next Month)
          - [ ] Implement predictive failure detection
          - [ ] Create comprehensive monitoring and observability
          - [ ] Design robust rollback and recovery procedures
          - [ ] Prepare failure analysis for multi-cloud expansion

          ## AI-Enhanced Recommendations

          $(if [[ -f "ai-failure-analysis.md" ]]; then
              echo "‚úÖ AI-enhanced analysis available - see attached artifacts"
              echo ""
              echo "Key AI insights:"
              head -20 ai-failure-analysis.md | tail -15
          else
              echo "‚ö†Ô∏è AI-enhanced analysis not available"
              echo "Configure REDHAT_AI_API_KEY for intelligent failure analysis"
          fi)

          ## Prevention Strategies

          1. **Enhanced Validation**
             - Implement comprehensive pre-flight checks
             - Validate all dependencies before deployment
             - Test connectivity to all required services

          2. **Improved Monitoring**
             - Real-time deployment progress monitoring
             - Early warning systems for potential failures
             - Automated health checks and validation

          3. **Better Error Handling**
             - Graceful failure handling with meaningful messages
             - Automatic retry mechanisms for transient failures
             - Comprehensive logging and debugging information

          ---
          *Generated by Smart Deployment Assistant*
          EOF

      - name: Upload failure analysis artifacts
        uses: actions/upload-artifact@v4
        with:
          name: failure-analysis-$(date +%Y%m%d)
          path: |
            failure-analysis-report.md
            failure-analysis.json
            ai-failure-analysis.md
          retention-days: 30

  create-deployment-issue:
    name: üìù Create Deployment Tracking Issue
    runs-on: ubuntu-latest
    needs: [pre-deployment-check, deployment-monitoring, failure-analysis]
    if: always() && (needs.pre-deployment-check.outputs.readiness_score < '70' || needs.deployment-monitoring.outputs.result == 'success' && env.DEPLOYMENT_ALERT_TRIGGERED == 'true')
    steps:
      - name: Create deployment assistance issue
        uses: actions/github-script@v7
        with:
          script: |
            const readinessScore = '${{ needs.pre-deployment-check.outputs.readiness_score }}' || 'N/A';
            const criticalIssues = '${{ needs.pre-deployment-check.outputs.critical_issues }}' || '0';
            const deploymentType = '${{ github.event.inputs.deployment_type }}';

            let title, body;

            if (readinessScore !== 'N/A' && parseInt(readinessScore) < 70) {
              title = `üö® Deployment Readiness Issues - Score: ${readinessScore}/100`;
              body = `# üö® Deployment Readiness Alert

              **Readiness Score**: ${readinessScore}/100
              **Critical Issues**: ${criticalIssues}
              **Target Cloud**: ${{ github.event.inputs.target_cloud || 'aws' }}
              **Environment**: ${{ github.event.inputs.environment || 'dev' }}

              ## Issues Detected
              - ‚ö†Ô∏è Deployment readiness score below acceptable threshold (70%)
              - üîç ${criticalIssues} critical issues identified

              ## Recommended Actions
              1. **Review readiness report** from workflow artifacts
              2. **Address critical configuration issues**
              3. **Re-run readiness check** after fixes
              4. **Proceed with deployment** only after score >70%

              ## Development Context
              - **Primary Focus**: AWS deployment stabilization
              - **Current Phase**: Active development and testing
              - **Multi-Cloud**: Azure/GCP expansion planned

              ---
              *Generated by Smart Deployment Assistant*`;
            } else {
              title = `üìä Deployment Monitoring Alert - Attention Required`;
              body = `# üìä Deployment Monitoring Alert

              **Alert Type**: ${deploymentType}
              **Success Rate**: ${{ env.ALERT_SUCCESS_RATE || 'N/A' }}%
              **Monitoring Period**: Last 24 hours

              ## Alert Details
              - üö® Deployment success rate below acceptable threshold
              - üìä Multiple deployment failures detected
              - üîç Pattern analysis and recommendations available

              ## Immediate Actions Required
              1. **Review monitoring reports** from workflow artifacts
              2. **Investigate failure patterns** and root causes
              3. **Implement recommended fixes**
              4. **Monitor deployment success rate** improvement

              ## Development Focus
              - **AWS Deployment**: Primary focus for stabilization
              - **Vault Integration**: Ensure reliable authentication
              - **Error Handling**: Improve resilience and recovery

              ---
              *Generated by Smart Deployment Assistant*`;
            }

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['deployment', 'aws', 'monitoring', 'ai-assistant']
            });

  summary:
    name: üìä Deployment Assistant Summary
    runs-on: ubuntu-latest
    needs: [pre-deployment-check, deployment-monitoring, failure-analysis]
    if: always()
    steps:
      - name: Generate deployment assistant summary
        run: |
          echo "üéâ Smart Deployment Assistant Complete!"
          echo ""
          echo "üìä Analysis Results:"
          echo "  Pre-deployment Check: ${{ needs.pre-deployment-check.result }} (Score: ${{ needs.pre-deployment-check.outputs.readiness_score }}/100)"
          echo "  Deployment Monitoring: ${{ needs.deployment-monitoring.result }}"
          echo "  Failure Analysis: ${{ needs.failure-analysis.result }}"
          echo ""
          echo "üéØ Focus Areas:"
          echo "  - AWS deployment readiness and monitoring"
          echo "  - Vault integration reliability"
          echo "  - Failure pattern analysis and prevention"
          echo "  - Multi-cloud expansion preparation"
          echo ""
          echo "üìã Key Insights:"
          echo "  - Deployment Type: ${{ github.event.inputs.deployment_type || 'automatic' }}"
          echo "  - Target Cloud: ${{ github.event.inputs.target_cloud || 'aws' }}"
          echo "  - Environment: ${{ github.event.inputs.environment || 'dev' }}"
          echo "  - AI Enhancement: ${{ github.event.inputs.ai_enhanced != 'false' && 'Enabled' || 'Available' }}"
          echo ""
          echo "üöÄ Next Steps:"
          echo "  1. Review generated reports and recommendations"
          echo "  2. Address any identified issues or improvements"
          echo "  3. Monitor deployment success rates"
          echo "  4. Plan multi-cloud expansion based on AWS experience"
