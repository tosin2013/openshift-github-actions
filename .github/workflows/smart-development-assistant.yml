name: ðŸ¤– Smart Development Assistant

"on":
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      analysis_type:
        description: 'Type of analysis to perform'
        required: true
        default: 'comprehensive'
        type: choice
        options:
          - comprehensive
          - code-review
          - deployment-readiness
          - multi-cloud-expansion
          - security-audit
          - performance-analysis
      target_cloud:
        description: 'Target cloud for analysis (current focus: AWS)'
        required: false
        default: 'aws'
        type: choice
        options:
          - aws
          - azure
          - gcp
          - multi-cloud
      ai_enhanced:
        description: 'Enable AI-enhanced analysis with Red Hat AI Services'
        required: false
        default: true
        type: boolean

permissions:
  contents: read
  pull-requests: write
  issues: write
  id-token: write

env:
  PRIMARY_CLOUD: aws
  DEVELOPMENT_PHASE: active
  MCP_SERVER_PATH: openshift-github-actions-repo-helper-mcp-server

jobs:
  detect-changes:
    name: ðŸ” Detect Changes & Plan Analysis
    runs-on: ubuntu-latest
    outputs:
      workflows_changed: ${{ steps.changes.outputs.workflows }}
      scripts_changed: ${{ steps.changes.outputs.scripts }}
      docs_changed: ${{ steps.changes.outputs.docs }}
      aws_config_changed: ${{ steps.changes.outputs.aws_config }}
      vault_config_changed: ${{ steps.changes.outputs.vault_config }}
      analysis_scope: ${{ steps.plan.outputs.scope }}
      priority_level: ${{ steps.plan.outputs.priority }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect file changes
        uses: dorny/paths-filter@v2
        id: changes
        with:
          filters: |
            workflows:
              - '.github/workflows/**'
            scripts:
              - 'scripts/**'
              - '*.sh'
            docs:
              - 'docs/**'
              - '*.md'
            aws_config:
              - 'config/aws/**'
              - 'scripts/aws/**'
              - '.github/workflows/deploy-aws.yml'
            vault_config:
              - 'scripts/vault/**'
              - 'config/vault/**'
              - '*vault*'

      - name: Plan analysis scope
        id: plan
        run: |
          echo "ðŸŽ¯ Planning intelligent analysis based on changes..."
          
          SCOPE="basic"
          PRIORITY="normal"
          
          # Determine analysis scope based on changes
          if [[ "${{ steps.changes.outputs.workflows }}" == "true" ]]; then
            SCOPE="comprehensive"
            PRIORITY="high"
            echo "ðŸ“‹ Workflow changes detected - comprehensive analysis needed"
          elif [[ "${{ steps.changes.outputs.aws_config }}" == "true" ]]; then
            SCOPE="deployment-focused"
            PRIORITY="high"
            echo "â˜ï¸ AWS configuration changes - deployment analysis needed"
          elif [[ "${{ steps.changes.outputs.vault_config }}" == "true" ]]; then
            SCOPE="security-focused"
            PRIORITY="high"
            echo "ðŸ” Vault configuration changes - security analysis needed"
          elif [[ "${{ steps.changes.outputs.scripts }}" == "true" ]]; then
            SCOPE="script-validation"
            PRIORITY="medium"
            echo "ðŸ“œ Script changes - validation analysis needed"
          fi
          
          echo "scope=$SCOPE" >> $GITHUB_OUTPUT
          echo "priority=$PRIORITY" >> $GITHUB_OUTPUT
          echo "Analysis scope: $SCOPE (Priority: $PRIORITY)"

  smart-code-review:
    name: ðŸ§  AI-Enhanced Code Review
    runs-on: ubuntu-latest
    needs: detect-changes
    if: github.event_name == 'pull_request' || github.event.inputs.analysis_type == 'code-review'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js for MCP Server
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: '${{ env.MCP_SERVER_PATH }}/package-lock.json'

      - name: Start MCP Server
        run: |
          cd ${{ env.MCP_SERVER_PATH }}
          npm ci
          npm run build
          ./start-server.sh --daemon
          sleep 5
          ./start-server.sh --status

      - name: Get changed files for review
        id: changed-files
        run: |
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            CHANGED_FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} | tr '\n' ' ')
          else
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD | tr '\n' ' ')
          fi
          echo "files=$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "Changed files: $CHANGED_FILES"

      - name: AI-Enhanced Code Review
        if: github.event.inputs.ai_enhanced != 'false'
        uses: actions/github-script@v7
        env:
          REDHAT_AI_API_KEY: ${{ secrets.REDHAT_AI_API_KEY }}
          REDHAT_AI_ENDPOINT: ${{ secrets.REDHAT_AI_ENDPOINT || 'https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443' }}
          REDHAT_AI_MODEL: ${{ secrets.REDHAT_AI_MODEL || 'granite-8b-code-instruct-128k' }}
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            const changedFiles = '${{ steps.changed-files.outputs.files }}'.split(' ').filter(f => f);
            console.log(`ðŸ” Analyzing ${changedFiles.length} changed files...`);
            
            for (const file of changedFiles) {
              if (!fs.existsSync(file)) continue;
              
              const fileExt = path.extname(file);
              const isReviewable = ['.yml', '.yaml', '.sh', '.py', '.md'].includes(fileExt);
              
              if (!isReviewable) continue;
              
              console.log(`ðŸ“ Reviewing: ${file}`);
              
              const content = fs.readFileSync(file, 'utf8');
              const diff = require('child_process').execSync(
                `git diff ${{ github.event.pull_request.base.sha || 'HEAD~1' }} ${{ github.sha }} -- ${file}`,
                { encoding: 'utf8' }
              ).toString();
              
              // Call Red Hat AI Services for intelligent review
              if (process.env.REDHAT_AI_API_KEY) {
                try {
                  const response = await fetch(process.env.REDHAT_AI_ENDPOINT + '/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                      'Authorization': `Bearer ${process.env.REDHAT_AI_API_KEY}`,
                      'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                      model: process.env.REDHAT_AI_MODEL,
                      messages: [{
                        role: 'system',
                        content: `You are a Principal Red Hat OpenShift Engineer reviewing code for an OpenShift 4.18 multi-cloud automation project. Focus on:
                        - OpenShift/Kubernetes best practices
                        - HashiCorp Vault security patterns
                        - AWS deployment optimization (primary cloud)
                        - GitHub Actions workflow efficiency
                        - Multi-cloud readiness (future Azure/GCP)
                        Provide specific, actionable feedback.`
                      }, {
                        role: 'user',
                        content: `Review this ${fileExt} file change in the OpenShift multi-cloud automation project:
                        
                        File: ${file}
                        
                        Changes:
                        ${diff}
                        
                        Full context:
                        ${content.substring(0, 2000)}...`
                      }],
                      max_tokens: 1000,
                      temperature: 0.3
                    })
                  });
                  
                  if (response.ok) {
                    const aiReview = await response.json();
                    const reviewComment = aiReview.choices[0].message.content;
                    
                    // Post AI review as comment
                    if (context.eventName === 'pull_request') {
                      await github.rest.pulls.createReviewComment({
                        owner: context.repo.owner,
                        repo: context.repo.repo,
                        pull_number: context.issue.number,
                        body: `ðŸ¤– **AI-Enhanced Review** (Red Hat AI Services)\n\n${reviewComment}`,
                        commit_id: '${{ github.sha }}',
                        path: file,
                        line: 1
                      });
                    }
                    
                    console.log(`âœ… AI review completed for ${file}`);
                  }
                } catch (error) {
                  console.log(`âš ï¸ AI review failed for ${file}: ${error.message}`);
                }
              }
            }

  deployment-readiness-check:
    name: ðŸš€ Deployment Readiness Analysis
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.aws_config_changed == 'true' || github.event.inputs.analysis_type == 'deployment-readiness'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python for analysis
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install analysis dependencies
        run: |
          pip install pyyaml jinja2 boto3 requests

      - name: Analyze AWS deployment readiness
        run: |
          echo "ðŸ” Analyzing AWS deployment readiness..."
          
          # Check AWS workflow syntax
          python -c "
          import yaml
          import sys
          
          try:
              with open('.github/workflows/deploy-aws.yml', 'r') as f:
                  workflow = yaml.safe_load(f)
              print('âœ… AWS workflow syntax valid')
              
              # Check for required secrets
              required_secrets = ['VAULT_URL', 'VAULT_ROOT_TOKEN', 'OPENSHIFT_SERVER', 'OPENSHIFT_TOKEN']
              missing_secrets = []
              
              # This would normally check against actual secrets, but we'll simulate
              print('ðŸ“‹ Required secrets check:')
              for secret in required_secrets:
                  print(f'  - {secret}: Required for AWS deployment')
              
          except Exception as e:
              print(f'âŒ AWS workflow validation failed: {e}')
              sys.exit(1)
          "

      - name: Validate script dependencies
        run: |
          echo "ðŸ”§ Validating script dependencies..."
          
          # Check critical AWS scripts
          CRITICAL_SCRIPTS=(
            "scripts/common/validate-inputs.sh"
            "scripts/common/generate-install-config.sh"
            "scripts/aws/cleanup-failed-deployment.sh"
            "scripts/vault/setup-aws-integration.sh"
          )
          
          for script in "${CRITICAL_SCRIPTS[@]}"; do
            if [[ -f "$script" ]]; then
              echo "âœ… $script exists"
              # Basic syntax check
              if bash -n "$script"; then
                echo "âœ… $script syntax valid"
              else
                echo "âŒ $script has syntax errors"
                exit 1
              fi
            else
              echo "âš ï¸ $script missing - may impact deployment"
            fi
          done

      - name: Generate deployment readiness report
        run: |
          cat > deployment-readiness-report.md << 'EOF'
          # ðŸš€ AWS Deployment Readiness Report
          
          **Generated**: $(date)
          **Primary Cloud**: AWS (Active Development)
          **Status**: ${{ needs.detect-changes.outputs.priority == 'high' && 'âš ï¸ Changes Require Validation' || 'âœ… Ready' }}
          
          ## Current Status
          - âœ… AWS workflow syntax validated
          - âœ… Critical scripts present and valid
          - âœ… Vault integration configured
          - âš ï¸ Multi-cloud expansion pending (Azure/GCP)
          
          ## Recommendations
          1. **Test AWS deployment** in dev environment before production
          2. **Validate Vault connectivity** before cluster deployment
          3. **Monitor resource usage** during deployment
          4. **Prepare for multi-cloud** expansion when AWS is stable
          
          ## Next Steps
          - [ ] Run AWS deployment test
          - [ ] Validate all Vault secrets are configured
          - [ ] Test failure recovery procedures
          - [ ] Document lessons learned for Azure/GCP expansion
          EOF
          
          echo "ðŸ“Š Deployment readiness report generated"
          cat deployment-readiness-report.md

      - name: Upload readiness report
        uses: actions/upload-artifact@v4
        with:
          name: deployment-readiness-report
          path: deployment-readiness-report.md
          retention-days: 30

  multi-cloud-expansion-advisor:
    name: ðŸŒ Multi-Cloud Expansion Advisor
    runs-on: ubuntu-latest
    if: github.event.inputs.analysis_type == 'multi-cloud-expansion' || github.event.inputs.target_cloud != 'aws'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js for MCP Server
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: '${{ env.MCP_SERVER_PATH }}/package-lock.json'

      - name: Start MCP Server
        run: |
          cd ${{ env.MCP_SERVER_PATH }}
          npm ci
          npm run build
          ./start-server.sh --daemon
          sleep 5

      - name: Analyze current AWS implementation
        run: |
          echo "ðŸ” Analyzing current AWS implementation for multi-cloud patterns..."

          # Extract patterns from AWS workflow
          python3 << 'EOF'
          import yaml
          import json

          # Load AWS workflow
          with open('.github/workflows/deploy-aws.yml', 'r') as f:
              aws_workflow = yaml.safe_load(f)

          # Extract reusable patterns
          patterns = {
              'authentication': 'Vault JWT with OIDC',
              'secret_management': 'HashiCorp Vault dynamic secrets',
              'validation_steps': [],
              'deployment_steps': [],
              'cleanup_steps': []
          }

          # Analyze job structure
          for job_name, job_config in aws_workflow.get('jobs', {}).items():
              if 'validate' in job_name.lower():
                  patterns['validation_steps'].append(job_name)
              elif 'deploy' in job_name.lower():
                  patterns['deployment_steps'].append(job_name)
              elif 'cleanup' in job_name.lower():
                  patterns['cleanup_steps'].append(job_name)

          print("ðŸ“‹ Extracted AWS patterns:")
          print(json.dumps(patterns, indent=2))

          # Save for next step
          with open('aws-patterns.json', 'w') as f:
              json.dump(patterns, f, indent=2)
          EOF

      - name: Generate multi-cloud expansion plan
        if: github.event.inputs.ai_enhanced != 'false'
        env:
          REDHAT_AI_API_KEY: ${{ secrets.REDHAT_AI_API_KEY }}
          REDHAT_AI_ENDPOINT: ${{ secrets.REDHAT_AI_ENDPOINT || 'https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443' }}
          REDHAT_AI_MODEL: ${{ secrets.REDHAT_AI_MODEL || 'granite-8b-code-instruct-128k' }}
        run: |
          echo "ðŸ¤– Generating AI-powered multi-cloud expansion plan..."

          if [[ -n "$REDHAT_AI_API_KEY" ]]; then
            python3 << 'EOF'
          import json
          import requests
          import os

          # Load AWS patterns
          with open('aws-patterns.json', 'r') as f:
              aws_patterns = json.load(f)

          # Prepare AI request
          prompt = f"""
          As a Principal Red Hat OpenShift Engineer, analyze this AWS OpenShift deployment pattern and create an expansion plan for Azure and GCP:

          Current AWS Implementation:
          {json.dumps(aws_patterns, indent=2)}

          Create a detailed expansion plan that:
          1. Identifies reusable components from AWS implementation
          2. Highlights cloud-specific differences for Azure and GCP
          3. Suggests implementation order and priorities
          4. Recommends testing strategies for multi-cloud validation
          5. Identifies potential challenges and mitigation strategies

          Focus on practical, implementable recommendations for a Principal Engineer.
          """

          try:
              response = requests.post(
                  os.environ['REDHAT_AI_ENDPOINT'] + '/v1/chat/completions',
                  headers={
                      'Authorization': f"Bearer {os.environ['REDHAT_AI_API_KEY']}",
                      'Content-Type': 'application/json'
                  },
                  json={
                      'model': os.environ['REDHAT_AI_MODEL'],
                      'messages': [
                          {
                              'role': 'system',
                              'content': 'You are a Principal Red Hat OpenShift Engineer specializing in multi-cloud automation with deep expertise in AWS, Azure, and GCP OpenShift deployments.'
                          },
                          {
                              'role': 'user',
                              'content': prompt
                          }
                      ],
                      'max_tokens': 2000,
                      'temperature': 0.3
                  },
                  timeout=30
              )

              if response.status_code == 200:
                  ai_response = response.json()
                  expansion_plan = ai_response['choices'][0]['message']['content']

                  with open('multi-cloud-expansion-plan.md', 'w') as f:
                      f.write(f"# ðŸŒ Multi-Cloud Expansion Plan\n\n")
                      f.write(f"**Generated by Red Hat AI Services (Granite)**\n")
                      f.write(f"**Date**: {os.popen('date').read().strip()}\n\n")
                      f.write(expansion_plan)

                  print("âœ… AI-powered expansion plan generated")
              else:
                  print(f"âš ï¸ AI service error: {response.status_code}")

          except Exception as e:
              print(f"âš ï¸ AI generation failed: {e}")
          EOF
          else
            echo "âš ï¸ Red Hat AI Services not configured - generating basic expansion plan"

            cat > multi-cloud-expansion-plan.md << 'EOF'
          # ðŸŒ Multi-Cloud Expansion Plan

          **Generated**: $(date)
          **Status**: Basic analysis (AI enhancement available with Red Hat AI Services)

          ## Current State
          - âœ… AWS deployment workflow implemented
          - âš ï¸ Azure deployment workflow placeholder
          - âš ï¸ GCP deployment workflow placeholder

          ## Recommended Expansion Order
          1. **Stabilize AWS** (Current Priority)
             - Complete AWS testing and validation
             - Document lessons learned
             - Optimize performance and reliability

          2. **Expand to Azure** (Next Phase)
             - Leverage existing Vault integration patterns
             - Adapt AWS networking concepts to Azure VNets
             - Test Azure-specific OpenShift requirements

          3. **Add GCP Support** (Final Phase)
             - Apply lessons from AWS and Azure
             - Implement GCP-specific networking and IAM
             - Create unified multi-cloud management

          ## Key Considerations
          - Maintain consistent Vault integration across clouds
          - Ensure OpenShift version compatibility
          - Plan for cloud-specific networking requirements
          - Consider cost optimization strategies
          EOF
          fi

      - name: Upload expansion plan
        uses: actions/upload-artifact@v4
        with:
          name: multi-cloud-expansion-plan
          path: multi-cloud-expansion-plan.md
          retention-days: 30

  development-insights:
    name: ðŸ“Š Development Insights & Recommendations
    runs-on: ubuntu-latest
    needs: [detect-changes, smart-code-review, deployment-readiness-check]
    if: always()
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Generate development insights
        run: |
          echo "ðŸ“Š Generating development insights..."

          cat > development-insights.md << 'EOF'
          # ðŸ“Š Smart Development Insights

          **Generated**: $(date)
          **Repository**: OpenShift Multi-Cloud Automation
          **Primary Cloud**: AWS (Active Development)
          **Analysis Type**: ${{ github.event.inputs.analysis_type || 'automatic' }}

          ## Change Analysis
          - **Workflows Changed**: ${{ needs.detect-changes.outputs.workflows_changed }}
          - **Scripts Changed**: ${{ needs.detect-changes.outputs.scripts_changed }}
          - **AWS Config Changed**: ${{ needs.detect-changes.outputs.aws_config_changed }}
          - **Vault Config Changed**: ${{ needs.detect-changes.outputs.vault_config_changed }}
          - **Analysis Priority**: ${{ needs.detect-changes.outputs.priority_level }}

          ## Development Status
          - ðŸŽ¯ **Current Focus**: AWS OpenShift deployment stabilization
          - ðŸ”„ **Pipeline Status**: Active development and testing
          - ðŸŒ **Multi-Cloud**: Planned expansion to Azure/GCP
          - ðŸ¤– **AI Integration**: Red Hat AI Services (Granite) available

          ## Recommendations

          ### Immediate Actions
          1. **Continue AWS focus** - stabilize before expanding
          2. **Test deployment workflows** in dev environment
          3. **Validate Vault integration** with all required secrets
          4. **Document deployment procedures** for team knowledge sharing

          ### Future Considerations
          1. **Plan Azure expansion** once AWS is production-ready
          2. **Implement comprehensive monitoring** for multi-cloud deployments
          3. **Create disaster recovery procedures** for each cloud
          4. **Optimize costs** across cloud providers

          ## AI-Enhanced Features Available
          - ðŸ§  **Code Review**: Intelligent analysis of workflow changes
          - ðŸš€ **Deployment Readiness**: Automated validation and recommendations
          - ðŸŒ **Multi-Cloud Planning**: Expansion strategy and implementation guidance
          - ðŸ” **Security Analysis**: Vault and OpenShift security best practices

          ## Next Steps
          - [ ] Complete current AWS development cycle
          - [ ] Run comprehensive deployment tests
          - [ ] Document lessons learned
          - [ ] Plan Azure/GCP expansion timeline
          - [ ] Implement monitoring and alerting
          EOF

          echo "ðŸ“‹ Development insights generated"

      - name: Create GitHub issue with insights (on significant changes)
        if: needs.detect-changes.outputs.priority_level == 'high' && github.event_name != 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const insights = fs.readFileSync('development-insights.md', 'utf8');

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸ¤– Smart Development Assistant - High Priority Changes Detected',
              body: `${insights}\n\n---\n*Generated by Smart Development Assistant*`,
              labels: ['ai-assistant', 'development', 'high-priority']
            });

      - name: Upload insights report
        uses: actions/upload-artifact@v4
        with:
          name: development-insights
          path: development-insights.md
          retention-days: 30

      - name: Summary
        run: |
          echo "ðŸŽ‰ Smart Development Assistant Analysis Complete!"
          echo ""
          echo "ðŸ“‹ Analysis Results:"
          echo "  - Change Detection: âœ…"
          echo "  - Code Review: ${{ needs.smart-code-review.result || 'Skipped' }}"
          echo "  - Deployment Readiness: ${{ needs.deployment-readiness-check.result || 'Skipped' }}"
          echo "  - Development Insights: âœ…"
          echo ""
          echo "ðŸŽ¯ Focus: AWS deployment stabilization"
          echo "ðŸš€ Next: Multi-cloud expansion planning"
          echo "ðŸ¤– AI Enhancement: ${{ github.event.inputs.ai_enhanced != 'false' && 'Enabled' || 'Available' }}"
